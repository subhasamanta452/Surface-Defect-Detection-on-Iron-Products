{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cc5006c-9a8f-45d9-a191-1610a0b4904f",
      "metadata": {
        "id": "8cc5006c-9a8f-45d9-a191-1610a0b4904f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import utils as vutils\n",
        "\n",
        "import os\n",
        "import random\n",
        "import argparse\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from models import Generator\n",
        "from helper_function import denormalized\n",
        "\n",
        "\n",
        "def load_params(model, new_param):\n",
        "    for p, new_p in zip(model.parameters(), new_param):\n",
        "        p.data.copy_(new_p)\n",
        "\n",
        "def resize(img,size=256):\n",
        "    return F.interpolate(img, size=size)\n",
        "\n",
        "def batch_generate(zs, netG, batch=8):\n",
        "    g_images = []\n",
        "    with torch.no_grad():\n",
        "        for i in range(len(zs)//batch):\n",
        "            g_images.append( netG(zs[i*batch:(i+1)*batch]).cpu() )\n",
        "        if len(zs)%batch>0:\n",
        "            g_images.append( netG(zs[-(len(zs)%batch):]).cpu() )\n",
        "    return torch.cat(g_images)\n",
        "\n",
        "def batch_save(images, folder_name):\n",
        "    if not os.path.exists(folder_name):\n",
        "        os.mkdir(folder_name)\n",
        "    for i, image in enumerate(images):\n",
        "        vutils.save_image(image.add(1).mul(0.5), folder_name+'/%d.jpg'%i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c151013d-4d8a-4cc8-abcc-0ec7d38f63df",
      "metadata": {
        "id": "c151013d-4d8a-4cc8-abcc-0ec7d38f63df"
      },
      "outputs": [],
      "source": [
        "# if __name__ == \"__main__\":\n",
        "#     parser = argparse.ArgumentParser(\n",
        "#         description='generate images'\n",
        "#     )\n",
        "#     parser.add_argument('--ckpt', type=str)\n",
        "#     parser.add_argument('--artifacts', type=str, default=\".\", help='path to artifacts.')\n",
        "#     parser.add_argument('--cuda', type=int, default=0, help='index of gpu to use')\n",
        "#     parser.add_argument('--start_iter', type=int, default=6)\n",
        "#     parser.add_argument('--end_iter', type=int, default=10)\n",
        "\n",
        "#     parser.add_argument('--dist', type=str, default='.')\n",
        "#     parser.add_argument('--size', type=int, default=256)\n",
        "#     parser.add_argument('--batch', default=16, type=int, help='batch size')\n",
        "#     parser.add_argument('--n_sample', type=int, default=2000)\n",
        "#     parser.add_argument('--big', action='store_true')\n",
        "#     parser.add_argument('--im_size', type=int, default=1024)\n",
        "#     parser.add_argument('--multiplier', type=int, default=10000, help='multiplier for model number')\n",
        "#     parser.set_defaults(big=False)\n",
        "#     args = parser.parse_args()\n",
        "class Args:\n",
        "    def __init__(self, ckpt=None, artifacts=\".\", cuda=0, start_iter=0, end_iter=10, dist='.', size= 512, batch=16, n_sample=2000, big=False, im_size= 512, multiplier=10000):\n",
        "        self.ckpt = ckpt\n",
        "        self.artifacts = artifacts\n",
        "        self.cuda = cuda\n",
        "        self.start_iter = start_iter\n",
        "        self.end_iter = end_iter\n",
        "        self.dist = dist\n",
        "        self.size = size\n",
        "        self.batch = batch\n",
        "        self.n_sample = n_sample\n",
        "        self.big = big\n",
        "        self.im_size = im_size\n",
        "        self.multiplier = multiplier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88a4e49f-2326-47d4-ac06-bfe70bd779b0",
      "metadata": {
        "id": "88a4e49f-2326-47d4-ac06-bfe70bd779b0"
      },
      "outputs": [],
      "source": [
        "args = Args()\n",
        "args.multiplier = 10\n",
        "args.artifacts =  \"train_results/result\"\n",
        "# args.artifacts =  \"../train_results/test1\"\n",
        "args.n_sample = 10\n",
        "args.batch = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9d8636d-6133-41a6-9f9d-fec1be10efba",
      "metadata": {
        "id": "b9d8636d-6133-41a6-9f9d-fec1be10efba",
        "outputId": "2bb4000c-2806-4585-b7b7-4dbb2816a9bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success\n"
          ]
        }
      ],
      "source": [
        "noise_dim = 256\n",
        "device = torch.device('cuda:%d'%(args.cuda))\n",
        "\n",
        "net_ig = Generator( ngf=64, nz=noise_dim, nc=3, im_size=args.im_size)#, big=args.big )\n",
        "net_ig.to(device)\n",
        "print(\"success\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a942bb41-7947-410a-8324-163998e21941",
      "metadata": {
        "scrolled": true,
        "id": "a942bb41-7947-410a-8324-163998e21941"
      },
      "outputs": [],
      "source": [
        "# epoch = 1000\n",
        "# ckpt = f\"{args.artifacts}/models/{epoch}.pth\"\n",
        "# checkpoint = torch.load(ckpt, map_location=lambda a,b: a)\n",
        "# # Remove prefix `module`.\n",
        "# checkpoint['g'] = {k.replace('module.', ''): v for k, v in checkpoint['g'].items()}\n",
        "# net_ig.load_state_dict(checkpoint['g'])\n",
        "# #load_params(net_ig, checkpoint['g_ema'])\n",
        "\n",
        "# #net_ig.eval()\n",
        "# print('load checkpoint success, epoch %d'%epoch)\n",
        "\n",
        "# net_ig.to(device)\n",
        "\n",
        "# # del checkpoint\n",
        "\n",
        "# dest = 'eval_%d'%(epoch)\n",
        "# dest = os.path.join(args.artifacts,dest, 'img')\n",
        "# os.makedirs(dest, exist_ok=True)\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     dpi = 100\n",
        "#     for i in tqdm(range(args.n_sample//args.batch)):\n",
        "#         noise = torch.randn(args.batch, noise_dim).to(device)\n",
        "#         g_imgs = net_ig(noise)[0]\n",
        "#         # g_imgs = resize(g_imgs,args.im_size) # resize the image using given dimension\n",
        "#         # print(g_imgs.shape)\n",
        "#         fig = plt.figure(figsize=(512/dpi, 512/dpi), dpi=dpi)\n",
        "#         ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
        "#         ax.set_axis_off()\n",
        "#         fig.add_axes(ax)\n",
        "#         img = np.transpose(denormalized(g_imgs).squeeze().cpu(),(1,2,0))\n",
        "#         plt.imshow(img)\n",
        "#         plt.savefig(f'{dest}/generated_{i}.jpg',pad_inches = 0)\n",
        "#         # plt.show()\n",
        "# #         # for j, g_img in enumerate( g_imgs ):\n",
        "# #         #     vutils.save_image(g_img.add(1).ml(0.5),\n",
        "# #         #         os.path.join(dist, '%d.png'%(i*args.batch+j)))#, normalize=True, range=(-1,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "034424c3-b9c8-45c7-8b09-160a8a3e05ef",
      "metadata": {
        "id": "034424c3-b9c8-45c7-8b09-160a8a3e05ef",
        "outputId": "99755b64-6296-4863-a828-05466be53745"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'train_results/result'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "args.artifacts"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccee58d2-1276-4590-b976-7c6a72078b2b",
      "metadata": {
        "id": "ccee58d2-1276-4590-b976-7c6a72078b2b"
      },
      "source": [
        "# For generating image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba4ad973",
      "metadata": {
        "id": "ba4ad973"
      },
      "outputs": [],
      "source": [
        "args = Args()\n",
        "args.multiplier = 10\n",
        "args.artifacts =  \"CR Scale RIS\"\n",
        "args.n_sample = 5000\n",
        "args.batch = 1\n",
        "noise_dim = 256\n",
        "device = torch.device('cuda:%d'%(args.cuda))\n",
        "\n",
        "net_ig = Generator( ngf=64, nz=noise_dim, nc=3, im_size=args.im_size)#, big=args.big )\n",
        "net_ig.to(device)\n",
        "print(\"success\")\n",
        "\n",
        "epoch = 60000\n",
        "ckpt = f\"{args.artifacts}/models/{epoch}.pth\"\n",
        "checkpoint = torch.load(ckpt, map_location=lambda a,b: a)\n",
        "# Remove prefix `module`.\n",
        "checkpoint['g'] = {k.replace('module.', ''): v for k, v in checkpoint['g'].items()}\n",
        "net_ig.load_state_dict(checkpoint['g'])\n",
        "#load_params(net_ig, checkpoint['g_ema'])\n",
        "print('load checkpoint success, epoch %d'%epoch)\n",
        "net_ig.to(device)\n",
        "\n",
        "# del checkpoint\n",
        "\n",
        "dest = 'eval_%d'%(epoch)\n",
        "\n",
        "dest = os.path.join(args.artifacts,dest, 'img')\n",
        "os.makedirs(dest, exist_ok=True)\n",
        "\n",
        "# net_ig.eval()\n",
        "# with torch.no_grad():\n",
        "#     dpi = 100\n",
        "#     for i in tqdm(range(args.n_sample//args.batch)):\n",
        "#         noise = torch.randn(args.batch, noise_dim).to(device)\n",
        "#         g_imgs = net_ig(noise)[0]\n",
        "#         # g_imgs = resize(g_imgs,args.im_size) # resize the image using given dimension\n",
        "#         # print(g_imgs.shape)\n",
        "#         fig = plt.figure(figsize=(512/dpi, 512/dpi), dpi=dpi)\n",
        "#         ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
        "#         ax.set_axis_off()\n",
        "#         fig.add_axes(ax)\n",
        "#         img = np.transpose(denormalized(g_imgs).squeeze().cpu(),(1,2,0))\n",
        "#         plt.savefig(f'{dest}/generated_{i}.jpg',pad_inches = 0)\n",
        "#         plt.imshow(img)\n",
        "\n",
        "net_ig.eval()\n",
        "with torch.no_grad():\n",
        "    dpi = 100\n",
        "    for i in tqdm(range(args.n_sample // args.batch)):\n",
        "        noise = torch.randn(args.batch, noise_dim).to(device)\n",
        "        g_imgs = net_ig(noise)[0]\n",
        "\n",
        "        fig = plt.figure(figsize=(512 / dpi, 512 / dpi), dpi=dpi)\n",
        "        ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
        "        ax.set_axis_off()\n",
        "        fig.add_axes(ax)\n",
        "\n",
        "        img = np.transpose(denormalized(g_imgs).squeeze().cpu().numpy(), (1, 2, 0))\n",
        "        ax.imshow(img)\n",
        "\n",
        "        plt.savefig(f'{dest}/generated_{i}.jpg', pad_inches=0, bbox_inches='tight')\n",
        "        plt.close(fig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "754c7dc3-f72a-43e2-bfa8-4e37a9d08384",
      "metadata": {
        "id": "754c7dc3-f72a-43e2-bfa8-4e37a9d08384",
        "outputId": "074d3143-bd91-4470-9457-9102b65ae131"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success\n",
            "load checkpoint success, epoch 62300\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████████| 100/100 [00:08<00:00, 11.72it/s]\n"
          ]
        }
      ],
      "source": [
        "args = Args()\n",
        "args.multiplier = 10\n",
        "args.artifacts =  \"train_results/CR Scale RIS\"\n",
        "args.n_sample = 100\n",
        "args.batch = 1\n",
        "noise_dim = 256\n",
        "device = torch.device('cuda:%d'%(args.cuda))\n",
        "\n",
        "net_ig = Generator( ngf=64, nz=noise_dim, nc=3, im_size=args.im_size)#, big=args.big )\n",
        "net_ig.to(device)\n",
        "print(\"success\")\n",
        "\n",
        "epoch = 62300\n",
        "ckpt = f\"{args.artifacts}/models/{epoch}.pth\"\n",
        "checkpoint = torch.load(ckpt, map_location=lambda a,b: a)\n",
        "# Remove prefix `module`.\n",
        "checkpoint['g'] = {k.replace('module.', ''): v for k, v in checkpoint['g'].items()}\n",
        "net_ig.load_state_dict(checkpoint['g'])\n",
        "#load_params(net_ig, checkpoint['g_ema'])\n",
        "print('load checkpoint success, epoch %d'%epoch)\n",
        "net_ig.to(device)\n",
        "\n",
        "# del checkpoint\n",
        "\n",
        "dest = 'eval_%d'%(epoch)\n",
        "\n",
        "dest = os.path.join(args.artifacts,dest, 'img')\n",
        "os.makedirs(dest, exist_ok=True)\n",
        "\n",
        "# net_ig.eval()\n",
        "# with torch.no_grad():\n",
        "#     dpi = 100\n",
        "#     for i in tqdm(range(args.n_sample//args.batch)):\n",
        "#         noise = torch.randn(args.batch, noise_dim).to(device)\n",
        "#         g_imgs = net_ig(noise)[0]\n",
        "#         # g_imgs = resize(g_imgs,args.im_size) # resize the image using given dimension\n",
        "#         # print(g_imgs.shape)\n",
        "#         fig = plt.figure(figsize=(512/dpi, 512/dpi), dpi=dpi)\n",
        "#         ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
        "#         ax.set_axis_off()\n",
        "#         fig.add_axes(ax)\n",
        "#         img = np.transpose(denormalized(g_imgs).squeeze().cpu(),(1,2,0))\n",
        "#         plt.savefig(f'{dest}/generated_{i}.jpg',pad_inches = 0)\n",
        "#         plt.imshow(img)\n",
        "\n",
        "net_ig.eval()\n",
        "with torch.no_grad():\n",
        "    dpi = 100\n",
        "    for i in tqdm(range(args.n_sample // args.batch)):\n",
        "        noise = torch.randn(args.batch, noise_dim).to(device)\n",
        "        g_imgs = net_ig(noise)[0]\n",
        "\n",
        "        fig = plt.figure(figsize=(512 / dpi, 512 / dpi), dpi=dpi)\n",
        "        ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
        "        ax.set_axis_off()\n",
        "        fig.add_axes(ax)\n",
        "\n",
        "        img = np.transpose(denormalized(g_imgs).squeeze().cpu().numpy(), (1, 2, 0))\n",
        "        ax.imshow(img)\n",
        "\n",
        "        plt.savefig(f'{dest}/generated_{i}.jpg', pad_inches=0, bbox_inches='tight')\n",
        "        plt.close(fig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8ebaff4-7fb5-4229-85f4-2b289c6f423a",
      "metadata": {
        "id": "a8ebaff4-7fb5-4229-85f4-2b289c6f423a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}